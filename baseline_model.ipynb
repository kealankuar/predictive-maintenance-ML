{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f7d1dc-9323-4c6b-9964-0fd1dffaf617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 8)\n",
      "X_test shape: (2000, 8)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load preprocessed data from pickle file\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "\n",
    "# Verify the data shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46495e1-ec52-4f1f-9e45-fc834f07bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3863211d-1e21-477c-828f-11ebb7823056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.973\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1939\n",
      "           1       0.64      0.26      0.37        61\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.81      0.63      0.68      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90267be-8c2a-41fe-9d01-4d3a9ae5b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Class Weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1939\n",
      "           1       0.13      0.85      0.22        61\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.56      0.83      0.56      2000\n",
      "weighted avg       0.97      0.82      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression with balanced class weights\n",
    "model_weighted = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_weighted = model_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Classification Report with Class Weights:\")\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0b8a15-bcd0-49ed-913e-75ecc36de820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set shape: (8000, 8)\n",
      "Resampled training set shape: (15444, 8)\n",
      "Classification Report with SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91      1939\n",
      "           1       0.13      0.80      0.22        61\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.56      0.82      0.56      2000\n",
      "weighted avg       0.97      0.83      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Original training set shape:\", X_train.shape)\n",
    "print(\"Resampled training set shape:\", X_train_res.shape)\n",
    "\n",
    "# Train logistic regression on the resampled data\n",
    "model_smote = LogisticRegression(max_iter=1000)\n",
    "model_smote.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the original test set\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report with SMOTE:\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acd3c90-f915-4c57-ab23-78835f261439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities (first 10): [0.37625996 0.50380729 0.19608927 0.12914718 0.50430679 0.53243277\n",
      " 0.2997286  0.77857433 0.08661634 0.00750935]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities for the failure class (class 1)\n",
    "y_prob = model_weighted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Optionally, inspect a few probability values\n",
    "print(\"Predicted probabilities (first 10):\", y_prob[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a5aba9-dd05-4e35-bf16-4efbf07bef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Threshold 0.2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73      1939\n",
      "           1       0.06      0.92      0.12        61\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.53      0.75      0.42      2000\n",
      "weighted avg       0.97      0.58      0.71      2000\n",
      "\n",
      "\n",
      "Classification Report for Threshold 0.3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      1939\n",
      "           1       0.08      0.89      0.15        61\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.54      0.78      0.48      2000\n",
      "weighted avg       0.97      0.69      0.79      2000\n",
      "\n",
      "\n",
      "Classification Report for Threshold 0.4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86      1939\n",
      "           1       0.10      0.85      0.18        61\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.55      0.80      0.52      2000\n",
      "weighted avg       0.97      0.76      0.84      2000\n",
      "\n",
      "\n",
      "Classification Report for Threshold 0.5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1939\n",
      "           1       0.13      0.85      0.22        61\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.56      0.83      0.56      2000\n",
      "weighted avg       0.97      0.82      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for t in thresholds:\n",
    "    # Convert probabilities to predictions based on the threshold\n",
    "    y_pred_tuned = np.where(y_prob >= t, 1, 0)\n",
    "    \n",
    "    # Print the classification report for each threshold\n",
    "    print(f\"\\nClassification Report for Threshold {t}:\")\n",
    "    print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df3021-20a3-4179-9541-8792ebb26954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
